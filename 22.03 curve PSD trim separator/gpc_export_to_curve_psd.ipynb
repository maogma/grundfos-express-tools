{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- Implement differences between efficiency/power curve PSDs\n",
    "- Update populated curve PSD to reflect Diameter units (Cell B3), Power (B4), Pwr/Eta cell (B5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports, File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from openpyxl import load_workbook\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the folder/file with the curve export csv\n",
    "myDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\10-19 Projects\\12 NBS Curve PSD Separation\\12.01 Original Files\"\n",
    "myFile = \"GPC NBS Curves.xlsx\"\n",
    "filePath = os.path.join(myDir, myFile)\n",
    "\n",
    "# This creates a dataframe of the curve export csv, and fills in the RPM(curve nominal) column\n",
    "data = pd.read_excel(filePath, sheet_name='GPC curves - removed duplicates', index_col=False)\n",
    "data['RPM(Pump data)'] = data['RPM(Pump data)'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This points to the curve PSD template to be used\n",
    "templateDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\30-39 Resources\\32 GXS\"\n",
    "template = \"SKB Blank Curve PSD - Efficiency_Metric.xlsx\"\n",
    "template = os.path.join(templateDir, template)\n",
    "\n",
    "# Create a local working copy to leave template unmodified\n",
    "outputPath = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\10-19 Projects\\12 NBS Curve PSD Separation\\12.02 Output Files\"\n",
    "workingCopy = os.path.join(outputPath, \"Populated Curve PSD.xlsx\")\n",
    "shutil.copyfile(template, workingCopy)\n",
    "wb = load_workbook(workingCopy)      \n",
    "tab_to_copy = wb['NEW']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trim_from_modelno(model_name:str):   \n",
    "    \" Takes model name: i.e. 012-070-2P-109_Std and returns 109\"\n",
    "    res = re.search(\"-(\\d+)_Std\", model_name)\n",
    "    curve_trim_size_mm = int(res.group(1))\n",
    "    return(curve_trim_size_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curveDataByPartNumber(data):\n",
    "    \"\"\"Creates dictionary of dataframes for each PN \"\"\"\n",
    "    import math\n",
    "    \n",
    "    # This will become a dictionary of dataframes of pns and curve data\n",
    "    dict_curveDataByPn = {}\n",
    "    \n",
    "    # Iterate through each row in pump curve data export \n",
    "    for index, value in data.iterrows():    \n",
    "        # When a PN is encountered:\n",
    "        if not math.isnan(value['ProductNumber']):\n",
    "            currentProductNumber = value['Model']\n",
    "            \n",
    "            # Resets list for each PN\n",
    "            listOfFlows = []\n",
    "            listOfHeads = []\n",
    "            listOfPow = []\n",
    "            listOfSpeeds = []\n",
    "            listOfNPSH = []\n",
    "            \n",
    "        # Recording Q/H values to lists\n",
    "        if value['RPM(Pump data)'] > 0:\n",
    "            listOfFlows.append(value['Q'])\n",
    "            listOfHeads.append(value['H'])\n",
    "            listOfNPSH.append(value['NPSH'])\n",
    "            listOfPow.append(value['P1'])\n",
    "            listOfSpeeds.append(value['RPM(Pump data)'])\n",
    "            \n",
    "        # At end of Q/H values, store in dataframe before moving to next PN, or when end of data is reached\n",
    "        if pd.isna(value['Q']) and pd.isna(value['H']) or (index == len(data)-1):    \n",
    "            zipped = list(zip(listOfFlows, listOfHeads, listOfPow, listOfNPSH, listOfSpeeds))\n",
    "            df = pd.DataFrame(zipped, columns=['Q','H','P1', 'NPSH','RPM'])\n",
    "\n",
    "            # Drop rows that have NaNs, then add df to dictionary\n",
    "            df = df.dropna()\n",
    "            dict_curveDataByPn.update({currentProductNumber:df})\n",
    "\n",
    "            continue\n",
    "\n",
    "    return dict_curveDataByPn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_a_curve(list_unique_curves):  \n",
    "    \"\"\" CREATE new tabs for each unique curve family \"\"\"\n",
    "    \n",
    "    global wb\n",
    "    \n",
    "    # Add a tab for each unique curve\n",
    "    for item in list_unique_curves: \n",
    "        \n",
    "        list_of_speeds = []\n",
    "        \n",
    "        # Add 1 tab\n",
    "        tabName = item\n",
    "        wb.copy_worksheet(tab_to_copy).title = tabName\n",
    "        \n",
    "        # Fill in all speeds in column A\n",
    "        # for key, value in curveDataDict[tabName].iterrows():\n",
    "        #     list_of_speeds.append(value['RPM'])\n",
    "        # speed_set = sorted(set(list_of_speeds), reverse=True)\n",
    "        # print(tabName, speed_set)  \n",
    "        \n",
    "        # for index, eachSpeed in enumerate(speed_set):\n",
    "        #     cell_name = \"{}{}\".format('A', 10+index)\n",
    "        #     curveSheet = wb[tabName]\n",
    "        #     curveSheet[cell_name].value = int(eachSpeed)\n",
    "       \n",
    "        def populate_cell(tab, cell_coord, cell_value):\n",
    "            cell_name = \"{}\".format(cell_coord)\n",
    "            curveSheet = wb[tab]\n",
    "            curveSheet[cell_name].value = cell_value\n",
    "\n",
    "        trim_size = extract_trim_from_modelno(tabName)\n",
    "        populate_cell(tabName, 'D7', trim_size)\n",
    "        populate_cell(tabName, 'A10', trim_size)\n",
    "        populate_cell(tabName, 'B3', 'mm')\n",
    "        populate_cell(tabName, 'B4', 'kW')\n",
    "        populate_cell(tabName, 'B5', 'Power')    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSpeedCells(my_df):\n",
    "    \"\"\" function to find which cell to start populating curve data based on RPM\"\"\"\n",
    "    # from openpyxl.utils.cell import coordinate_from_string, column_index_from_string, get_column_letter\n",
    "    from openpyxl.utils.cell import get_column_letter\n",
    "    speedCells = []\n",
    "    \n",
    "    max_cols = 21 * len(my_df.RPM.unique())\n",
    "    row = 7    \n",
    "    first_col = 4\n",
    "    diameter_cols = list(range(first_col,max_cols,21))\n",
    "    \n",
    "    for item in diameter_cols:\n",
    "        col = get_column_letter(item)\n",
    "        cell_coordinate = \"{}{}\".format(col,row)\n",
    "        speedCells.append(cell_coordinate)      \n",
    "\n",
    "    return(speedCells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curveFiller(pn_vs_curves_dict):\n",
    "    \"\"\" fills curve tables in each tab \"\"\"\n",
    "    global wb\n",
    "    cellName = 'D7' \n",
    "    first_row_offset = 3\n",
    "\n",
    "    # Iterate through each tab in workbook\n",
    "    for sheet in wb.worksheets:\n",
    "        sheetname = sheet.title\n",
    "\n",
    "        # Only process tabs that contain curve data\n",
    "        if sheetname[-4:] == \"_Std\":\n",
    "            \n",
    "            for model_name, curve_dataframe in pn_vs_curves_dict.items():\n",
    "                if model_name == sheetname:\n",
    "\n",
    "                    # Iterate through dataframe row by row and fill out each row in PSD    \n",
    "                    for key, value in curve_dataframe.iterrows():\n",
    "                        sheet[cellName].offset(first_row_offset + key, 0).value = value['Q']\n",
    "                        sheet[cellName].offset(first_row_offset + key, 1).value = value['H']\n",
    "                        sheet[cellName].offset(first_row_offset + key, 7).value = value['Q']\n",
    "                        # sheet[cellName].offset(first_row_offset + key, 8).value = value['Eta1']\n",
    "                        sheet[cellName].offset(first_row_offset + key, 8).value = value['P1']\n",
    "                        sheet[cellName].offset(first_row_offset + key,14).value = value['Q']\n",
    "                        sheet[cellName].offset(first_row_offset + key,15).value = value['NPSH']      \n",
    "    return   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dictionary with part numbers as keys, curves as dataframes for each key\n",
    "curveDataDict = curveDataByPartNumber(data)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates list of which part numbers share curve data\n",
    "uniqueCurvePartnumbers = list(curveDataDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds curve tabs for each unique curve\n",
    "add_a_curve(uniqueCurvePartnumbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fills each new curve tab\n",
    "curveFiller(curveDataDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save changes to excel sheet\n",
    "wb.save(workingCopy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d89935b22884bac8e846ef6a5fb14ff565b7e382ac92ebe1031401d4b8e3f29"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
