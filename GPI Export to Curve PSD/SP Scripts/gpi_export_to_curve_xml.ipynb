{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- Implement differences between efficiency/power curve PSDs\n",
    "- Update populated curve PSD to reflect Diameter units (Cell B3), Power (B4), Pwr/Eta cell (B5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports, File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import shutil\n",
    "from openpyxl import load_workbook\n",
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "curve_dict = {\n",
    "    'Flow':'Q',\n",
    "    'Head':'H',\n",
    "    'Power':'P2',\n",
    "    'Efficiency':'Eta2',\n",
    "    'NPSH':'NPSH'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class to hold each curve by product number/trim\n",
    "class Curve:\n",
    "    def __init__(self, pumpModel, dataframe):\n",
    "        self.name = pumpModel\n",
    "        self.pn = dataframe.iloc[0]['ProductNumber']\n",
    "        self.df = dataframe\n",
    "        self.frequency = dataframe.iloc[0]['Frequency']\n",
    "        self.phase = dataframe.iloc[0]['Phase']\n",
    "        self.trims = self.df['RPM(Curve nominal)'].unique().tolist()\n",
    "        self.trim_curves = {}\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Pump Model(name={self.name}, trim={self.trim}, dataframe=\\n{self.df})\"\n",
    "\n",
    "\n",
    "    def return_xy_points(self, curveType:str):\n",
    "        '''Returns 2 lists: 1 - flow values, 2 - Head or Power or Efficiency or NPSH'''\n",
    "        x_values = self.df['Q'].tolist()\n",
    "        y_values = self.df[curve_dict[curveType]].tolist()\n",
    "        return x_values, y_values\n",
    "    \n",
    "\n",
    "    def create_grouped_trim_curves(self):\n",
    "        '''Group df by the trim/speed column'''\n",
    "        grouped = self.df.groupby('RPM(Curve nominal)')\n",
    "        # Create mini dataframes for each trim within a pump model\n",
    "        for group_trim, trim_df in grouped:\n",
    "            self.trim_curves[group_trim] = trim_df[['Q','H','P2', 'P1',\t'Eta2',\t'Eta1',\t'NPSH']]\n",
    "        return\n",
    "    \n",
    "\n",
    "    # Define the function to calculate new values based on affinity laws\n",
    "    # def apply_affinity_laws(row):\n",
    "    #     N1, N2 = row['N1'], row['N2']\n",
    "    #     Q2 = row['Q1'] * (N2 / N1)\n",
    "    #     H2 = row['H1'] * (N2 / N1)**2\n",
    "    #     P2 = row['P1'] * (N2 / N1)**3\n",
    "    #     eta2 = np.nan\n",
    "    #     eta1 = np.nan\n",
    "    #     return pd.Series([Q2, H2, P2, eta2], index=['Q2', 'H2', 'P2', 'eta2'])\n",
    "\n",
    "\n",
    "\n",
    "    def create_new_trim_df(self, n2):\n",
    "        # Calculate new values for flow, head, power, npsh)\n",
    "        flow_mult_exp = 1\n",
    "        npsh_head_mult_exp = 2\n",
    "        power_mult_exp = 3\n",
    "        \n",
    "        n1 = self.max_trim\n",
    "        df = self.trim_curves[n1]\n",
    "\n",
    "        \n",
    "        df['Q2'] = df['Q'].apply(lambda x: x * ((n2/n1)**flow_mult_exp))\n",
    "        print(f\"original col: {df['Q']}\")\n",
    "        print(f\"new col: {df['Q2']}\")\n",
    "        df['H'] = df['Q'].apply(lambda x: x * ((n2/n1)**npsh_head_mult_exp))\n",
    "        df['NPSH'] = df['NPSH'].apply(lambda x: x * ((n2/n1)**npsh_head_mult_exp))\n",
    "        df['P2'] = df['P2'].apply(lambda x: x * ((n2/n1)**power_mult_exp))\n",
    "        df['P1'] = df['P1'].apply(lambda x: x * ((n2/n1)**power_mult_exp))\n",
    "        df['Eta2'] = np.nan\n",
    "        df['Eta1'] = np.nan\n",
    "\n",
    "        # Add new dataframe to dictionary trim_curves\n",
    "        self.trim_curves[n2] = df\n",
    "        return\n",
    "\n",
    "\n",
    "    @property\n",
    "    def max_trim(self):\n",
    "        return max(self.trims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_data(action: str) -> None:\n",
    "#     \"\"\"\n",
    "#     Processes data based on the specified action.\n",
    "\n",
    "#     Parameters:\n",
    "#     action (str): The action to perform. Available options are:\n",
    "#         - 'load': Load the data.\n",
    "#         - 'save': Save the data.\n",
    "#         - 'delete': Delete the data.\n",
    "\n",
    "#     Raises:\n",
    "#     ValueError: If the action is not one of the available options.\n",
    "#     \"\"\"\n",
    "\n",
    "#     available_actions = ['load', 'save', 'delete']\n",
    "\n",
    "#     if action not in available_actions:\n",
    "#         raise ValueError(f\"Invalid action. Available options are: {', '.join(available_actions)}\")\n",
    "\n",
    "#     # Process the data based on the action\n",
    "#     if action == 'load':\n",
    "#         print(\"Loading data...\")\n",
    "#         # Add your loading logic here\n",
    "#     elif action == 'save':\n",
    "#         print(\"Saving data...\")\n",
    "#         # Add your saving logic here\n",
    "#     elif action == 'delete':\n",
    "#         print(\"Deleting data...\")\n",
    "#         # Add your deleting logic here\n",
    "\n",
    "# # Example usage:\n",
    "# process_data('load')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the folder/file with the curve export csv\n",
    "# myDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\1 - PROJECTS\\SPE Integration\\SPE_PumpCurve\"\n",
    "myDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\2 - AREAS\\Alpha GXS Integration\\Curve PSD\\Archive\"\n",
    "myFile = \"Pump Curves - ALPHA.csv\"\n",
    "filePath = os.path.join(myDir, myFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\104092\\AppData\\Local\\Temp\\ipykernel_69568\\2295600585.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_non_nan['Product name'] = df_non_nan['Product name'].ffill()\n",
      "C:\\Users\\104092\\AppData\\Local\\Temp\\ipykernel_69568\\2295600585.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_non_nan['RPM(Curve nominal)'] = df_non_nan['RPM(Curve nominal)'].ffill()\n"
     ]
    }
   ],
   "source": [
    "# This separates the GPI curve export by groups according to ProductNumber\n",
    "# df= pd.read_csv(filePath, sep=\";\", index_col=False, skip_blank_lines=False) # FOR SPE\n",
    "df= pd.read_csv(filePath, index_col=False, skip_blank_lines=False) # For ALPHA Testing\n",
    "df = df.replace(',','.', regex=True)\n",
    "\n",
    "# Drop NaN rows before grouping\n",
    "df_non_nan = df.dropna(how='all')\n",
    "\n",
    "# Forward fill productname and curve nominal columns for grouping \n",
    "df_non_nan['Product name'] = df_non_nan['Product name'].ffill()\n",
    "df_non_nan['RPM(Curve nominal)'] = df_non_nan['RPM(Curve nominal)'].ffill()\n",
    "\n",
    "# Group by the pump model column\n",
    "grouped = df_non_nan.groupby('Product name')\n",
    "\n",
    "# Make a model from each group \n",
    "group_objects = {}\n",
    "for pumpModel, group_df in grouped:\n",
    "    group_object = Curve(pumpModel=pumpModel, dataframe=group_df)\n",
    "    group_object.create_grouped_trim_curves()\n",
    "    group_objects[(f'{pumpModel}')] = group_object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m object_name \u001b[38;5;129;01min\u001b[39;00m group_objects:\n\u001b[0;32m      5\u001b[0m     model_object \u001b[38;5;241m=\u001b[39m group_objects[object_name]\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mmodel_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_new_trim_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Apply the function to each row\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# df[['Q2', 'H2', 'P2', 'eta2']] = df.apply(apply_affinity_laws, axis=1)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[166], line 55\u001b[0m, in \u001b[0;36mCurve.create_new_trim_df\u001b[1;34m(self, n2)\u001b[0m\n\u001b[0;32m     51\u001b[0m n1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_trim\n\u001b[0;32m     52\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrim_curves[n1]\n\u001b[1;32m---> 55\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m*\u001b[39m ((n2\u001b[38;5;241m/\u001b[39mn1)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflow_mult_exp))\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal col: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew col: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "# Iterate through list of models and new speeds that need to be created\n",
    "n2 = 1800\n",
    "\n",
    "for object_name in group_objects:\n",
    "    model_object = group_objects[object_name]\n",
    "    model_object.create_new_trim_df(n2)\n",
    "    \n",
    "    # Apply the function to each row\n",
    "    # df[['Q2', 'H2', 'P2', 'eta2']] = df.apply(apply_affinity_laws, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING \n",
    "# x_list, y_list = group_objects['ALPHA1 15-55F'].return_xy_points('Head')\n",
    "\n",
    "group_objects['ALPHA1 15-55F'].trim_curves[3500]\n",
    "# group_objects['ALPHA1 15-55F'].trim_curves[1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Leverage Luke's code to write these to xml for deployment\n",
    "\n",
    "# Write to excel for data validation, or plot with matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_min_max_values(myList):\n",
    "\n",
    "#     min_speed = myList[-1]\n",
    "#     max_speed = myList[0]\n",
    "#     max_nominal = max_speed\n",
    "\n",
    "#     return min_speed, max_nominal, max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findSpeedCells(my_df):\n",
    "#     \"\"\" function to find which cell to start populating curve data based on RPM\"\"\"\n",
    "#     # from openpyxl.utils.cell import coordinate_from_string, column_index_from_string, get_column_letter\n",
    "#     from openpyxl.utils.cell import get_column_letter\n",
    "#     speedCells = []\n",
    "    \n",
    "#     max_cols = 21 * len(my_df.RPM.unique())\n",
    "#     row = 7    \n",
    "#     first_col = 4\n",
    "#     diameter_cols = list(range(first_col,max_cols,21))\n",
    "    \n",
    "#     for item in diameter_cols:\n",
    "#         col = get_column_letter(item)\n",
    "#         cell_coordinate = \"{}{}\".format(col,row)\n",
    "#         speedCells.append(cell_coordinate)      \n",
    "\n",
    "#     return(speedCells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curveDataByPartNumber(data) -> dict:\n",
    "    \"\"\"Creates dictionary of dataframes for each PN \"\"\"\n",
    "    import math\n",
    "    \n",
    "    # This will become a dictionary with keys=pns and values=curve_data_dataframes\n",
    "    dict_curveDataByPn = {}\n",
    "    \n",
    "    # Iterate through each row in pump curve data export \n",
    "    for index, value in data.iterrows():    \n",
    "        \n",
    "        # When a PN is encountered:\n",
    "        # if not math.isnan(value['ProductNumber']):\n",
    "        #     currentProductNumber = int(value['ProductNumber'])\n",
    "        if type(value['ProductNumber']) == str:\n",
    "            currentProductNumber = value['ProductNumber']\n",
    "            \n",
    "            # Resets list for each PN\n",
    "            listOfFlows = []\n",
    "            listOfHeads = []\n",
    "            listOfPow = []\n",
    "            listOfSpeeds = []\n",
    "            listOfNPSH = []\n",
    "            \n",
    "        # Recording Q/H values to lists\n",
    "        if value['RPM(Curve nominal)'] > 0:\n",
    "            listOfFlows.append(value['Q'])\n",
    "            listOfHeads.append(value['H'])\n",
    "            listOfNPSH.append(value['NPSH'])\n",
    "            listOfPow.append(value['P1'])\n",
    "            listOfSpeeds.append(value['RPM(Curve nominal)'])\n",
    "            \n",
    "        # At end of Q/H values, store in dataframe before moving to next PN, or when end of data is reached\n",
    "        if pd.isna(value['Q']) and pd.isna(value['H']) or (index == len(data)-1):    \n",
    "            zipped = list(zip(listOfFlows, listOfHeads, listOfPow, listOfNPSH, listOfSpeeds))\n",
    "            df = pd.DataFrame(zipped, columns=['Q','H','P1', 'NPSH','RPM'])\n",
    "\n",
    "            # Drop rows that have NaNs, then add df to dictionary\n",
    "            df = df.dropna()\n",
    "            dict_curveDataByPn.update({currentProductNumber:df})\n",
    "\n",
    "            continue\n",
    "\n",
    "    return dict_curveDataByPn\n",
    "    \n",
    "# Creates dictionary with part numbers as keys, curves as dataframes for each key\n",
    "curveDataDict = curveDataByPartNumber(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curveDataMatches(curveDataDict):  \n",
    "    \"\"\" Create list of PNs that share curve data \"\"\"\n",
    "\n",
    "    curveDataCopy = curveDataDict.copy()\n",
    "    listOfLists = []\n",
    "    \n",
    "    for eachPN, eachDF in curveDataDict.items():  \n",
    "        listOfPNs = []\n",
    "        for key, value in curveDataCopy.items():\n",
    "            if value.equals(eachDF):\n",
    "                listOfPNs.append(key)\n",
    "        \n",
    "        if listOfPNs not in listOfLists:\n",
    "            listOfLists.append(listOfPNs)\n",
    "    \n",
    "    # print(f'list of lists: {listOfLists}')\n",
    "    # print(f'list of pns: {listOfPNs}')\n",
    "    \n",
    "    return listOfLists\n",
    "    \n",
    "# Creates list of which part numbers share curve data\n",
    "uniqueCurvePartnumbers = curveDataMatches(curveDataDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_a_curve(list_unique_curves):  # WORKING. DO NOT MODIFY YET\n",
    "#     \"\"\" CREATE new tabs for each unique curve family \"\"\"\n",
    "    \n",
    "#     global wb\n",
    "#     tab_to_copy = wb['NEW'] \n",
    "    \n",
    "#     partnumbers = []\n",
    "#     min_speeds = []\n",
    "#     nom_speeds = []\n",
    "#     max_speeds = []\n",
    "    \n",
    "#     # Add a tab for each unique curve\n",
    "#     for item in list_unique_curves: \n",
    "        \n",
    "#         list_of_speeds = []\n",
    "\n",
    "#         # Add 1 tab\n",
    "#         tabName = str(item[0])\n",
    "#         # print(tabName)\n",
    "#         wb.copy_worksheet(tab_to_copy).title = tabName\n",
    "\n",
    "#         # Fill in all speeds/trims in column A\n",
    "#         for key, value in curveDataDict[tabName].iterrows():\n",
    "#             list_of_speeds.append(value['RPM'])\n",
    "        \n",
    "#         speed_set = sorted(set(list_of_speeds), reverse=True)\n",
    "#         # print(tabName, speed_set)  \n",
    "        \n",
    "#         for index, eachSpeed in enumerate(speed_set):\n",
    "#             cell_name = \"{}{}\".format('A', 10+index)\n",
    "#             curveSheet = wb[tabName]\n",
    "#             curveSheet[cell_name].value = int(eachSpeed)\n",
    "\n",
    "#             min_rpm, nom_rpm, max_rpm = get_min_max_values(speed_set)\n",
    "            \n",
    "#             partnumbers.append(tabName)\n",
    "#             min_speeds.append(min_rpm)\n",
    "#             nom_speeds.append(nom_rpm)\n",
    "#             max_speeds.append(max_rpm)\n",
    "            \n",
    "#             zipped = list(zip(partnumbers, min_speeds, nom_speeds, max_speeds))\n",
    "#             df = pd.DataFrame(zipped, columns=['Partnumber','Min RPM','Nominal RPM', 'Max RPM'])\n",
    "        \n",
    "#     return df\n",
    "    \n",
    "# # Adds curve tabs for each unique curve\n",
    "# # minmax_speeds_df = add_a_curve(uniqueCurvePartnumbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 1 curve tab to workbook for every unique curve found (avoids duplicating data in SKB)\n",
    "for item in uniqueCurvePartnumbers: \n",
    "    tabName = str(item[0])\n",
    "    wb.copy_worksheet(wb['NEW']).title = tabName # Creates and renames blank PSD Tab as template for each new curve tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variable_speeds(df) -> list:\n",
    "    ''' Takes curve data in dataframe format, and returns list of all unique speeds for variable speed pumps'''\n",
    "    list_of_rpms = []\n",
    "\n",
    "    for key, value in df.iterrows():\n",
    "        list_of_rpms.append(value['RPM'])\n",
    "    \n",
    "    list_of_rpms = sorted(set(list_of_rpms), reverse=True)\n",
    "\n",
    "    return list_of_rpms\n",
    "\n",
    "# Iterate through list of unique curve names, and populate the corresponding workbook tab\n",
    "for uniqueCurve in uniqueCurvePartnumbers:\n",
    "    curveSheet = wb[uniqueCurve[0]]\n",
    "    curve_data_df = curveDataDict[uniqueCurve[0]]\n",
    "    \n",
    "    # Fill Speed or trim in column A\n",
    "    speed_set = extract_variable_speeds(curve_data_df)\n",
    "\n",
    "    for index, eachSpeed in enumerate(speed_set):\n",
    "        cell_name = \"{}{}\".format('A', 10+index)\n",
    "        curveSheet[cell_name].value = int(eachSpeed)\n",
    "        # print(f'For PN: {uniqueCurve[0]} -> cell: {cell_name} should have value: {int(eachSpeed)}. It currently has: {curveSheet[cell_name].value}')\n",
    "\n",
    "    # Fill Curve, power/eff, NPSH data\n",
    "    cellName = 'D7' \n",
    "    first_row_offset = 3\n",
    "\n",
    "    for key, value in curve_data_df.iterrows():\n",
    "        curveSheet[cellName].offset(first_row_offset + key, 0).value = value['Q']\n",
    "        curveSheet[cellName].offset(first_row_offset + key, 1).value = value['H']\n",
    "        curveSheet[cellName].offset(first_row_offset + key, 7).value = value['Q']\n",
    "        # curveSheet[cellName].offset(first_row_offset + key, 8).value = value['Eta1']\n",
    "        curveSheet[cellName].offset(first_row_offset + key, 8).value = value['P1']\n",
    "        curveSheet[cellName].offset(first_row_offset + key,14).value = value['Q']\n",
    "        curveSheet[cellName].offset(first_row_offset + key,15).value = value['NPSH']\n",
    "\n",
    "    # Fill out corresponding row in Curve Header Data Tab\n",
    "    # sheet = wb[\"Curve Header Data\"]\n",
    "    # sheet['B7'] = \"SP\"\n",
    "\n",
    "    # cellName = 'A1' \n",
    "    # first_row_offset = 10\n",
    "\n",
    "    # for index, speedData in curve_data_df.iterrows():\n",
    "    #     print(f'Current pn: {uniqueCurve[0]}')\n",
    "    #     print(f'{speedData}')\n",
    "\n",
    "\n",
    "    #     sheet[cellName].offset((first_row_offset + index), 0).value = uniqueCurve[0]\n",
    "    #     sheet[cellName].offset((first_row_offset + index), 2).value = speedData['RPM']\n",
    "    #     sheet[cellName].offset((first_row_offset + index), 6).value = speedData['RPM']\n",
    "    #     sheet[cellName].offset((first_row_offset + index), 7).value = speedData['RPM']\n",
    "    #     sheet[cellName].offset((first_row_offset + index), 8).value = speedData['RPM']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def speeds_for_curve_header_data():\n",
    "    # # partnumbers = []\n",
    "    # # min_speeds = []\n",
    "    # # nom_speeds = []\n",
    "    # # max_speeds = []\n",
    "\n",
    "    # min_rpm, nom_rpm, max_rpm = get_min_max_values(speed_set)\n",
    "\n",
    "    # partnumbers.append(tabName)\n",
    "    # min_speeds.append(min_rpm)\n",
    "    # nom_speeds.append(nom_rpm)\n",
    "    # max_speeds.append(max_rpm)\n",
    "\n",
    "    # zipped = list(zip(partnumbers, min_speeds, nom_speeds, max_speeds))\n",
    "    # df = pd.DataFrame(zipped, columns=['Partnumber','Min RPM','Nominal RPM', 'Max RPM'])\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fill out Curve Header Data Tab\n",
    "# newPumpFamilyName = \"SP\"\n",
    "# sheet = wb[\"Curve Header Data\"]\n",
    "# sheet['B7'] = newPumpFamilyName\n",
    "\n",
    "# cellName = 'A1' \n",
    "# first_row_offset = 10\n",
    "\n",
    "# for index, speedData in df_of_speeds.iterrows():\n",
    "#     sheet[cellName].offset((first_row_offset + index), 0).value = speedData['Partnumber']\n",
    "#     sheet[cellName].offset((first_row_offset + index), 2).value = speedData['Nominal RPM']\n",
    "#     sheet[cellName].offset((first_row_offset + index), 6).value = speedData['Nominal RPM']\n",
    "#     sheet[cellName].offset((first_row_offset + index), 7).value = speedData['Min RPM']\n",
    "#     sheet[cellName].offset((first_row_offset + index), 8).value = speedData['Max RPM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillCurveHeaderDataTab(df_of_speeds):\n",
    "    global wb\n",
    "    newPumpFamilyName = \"SP\"\n",
    "    sheet = wb[\"Curve Header Data\"]\n",
    "\n",
    "    cellName = 'A1' \n",
    "    first_row_offset = 10\n",
    "\n",
    "    for index, speedData in df_of_speeds.iterrows():\n",
    "        sheet[cellName].offset((first_row_offset + index), 0).value = speedData['Partnumber']\n",
    "        sheet[cellName].offset((first_row_offset + index), 2).value = speedData['Nominal RPM']\n",
    "        sheet[cellName].offset((first_row_offset + index), 6).value = speedData['Nominal RPM']\n",
    "        sheet[cellName].offset((first_row_offset + index), 7).value = speedData['Min RPM']\n",
    "        sheet[cellName].offset((first_row_offset + index), 8).value = speedData['Max RPM']\n",
    "\n",
    "    sheet['B7'] = newPumpFamilyName\n",
    "    wb.save(workingCopy)\n",
    "\n",
    "    return\n",
    "\n",
    "# fillCurveHeaderDataTab(minmax_speeds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of PNs that share curve data, and inserts tab to illustrate\n",
    "curveFamilySheet = wb.create_sheet(\"Shared Curves\", 2)\n",
    "\n",
    "for index, family in enumerate(uniqueCurvePartnumbers):\n",
    "    row = index + 1  # Excel doesn't like 0-indexes\n",
    "\n",
    "    # Fill 1st column in spreadsheet\n",
    "    curveFamilySheet.cell(row=row, column=1).value = \"Curve \" + str(row)\n",
    "\n",
    "    # Fill 2nd (or more) columns with partnumbers that share curves\n",
    "    if len(family) == 1:\n",
    "        curveFamilySheet.cell(row=row, column=2).value = family[0]\n",
    "        # print('length of family is 1')\n",
    "    else:\n",
    "        curveFamilySheet.cell(row=row, column=2).value = family[0]\n",
    "        curveFamilySheet.cell(row=row, column=3).value = family[1]\n",
    "        # print(f'family[0]: {family[0]}, family[1]: {family[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save changes to excel sheet\n",
    "wb.save(workingCopy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87f84caef9bf4416e38bbc24a276e63f300c10e2c66374eecdd02b2ff25e7d04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
