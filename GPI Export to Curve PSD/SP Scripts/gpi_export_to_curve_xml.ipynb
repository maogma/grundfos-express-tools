{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports, File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "curve_dict = {\n",
    "    'Flow':'Q',\n",
    "    'Head':'H',\n",
    "    'Power':'P2',\n",
    "    'Efficiency':'Eta2',\n",
    "    'NPSH':'NPSH'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the folder/file with the curve export csv\n",
    "myDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\1 - PROJECTS\\SPE Integration\\SPE_PumpCurve\"\n",
    "myFile = \"PumpCurves.csv\"\n",
    "filePath = os.path.join(myDir, myFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function Definitions and Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affinity Laws function\n",
    "def apply_affinity_laws(row, n2, n1):\n",
    "    N1, N2 = n1, n2\n",
    "    Q2 = row['Q'] * (N2 / N1)\n",
    "    H2 = row['H'] * (N2 / N1)**2\n",
    "    NPSH2 = row['NPSH'] * (N2 / N1)**2\n",
    "    P22 = row['P2'] * (N2 / N1)**3\n",
    "    # P12 = row['P1'] * (N2 / N1)**3\n",
    "    rpm_pump_data = row['RPM(Pump data)']\n",
    "    rpm_curve_nom = row['RPM(Curve nominal)']\n",
    "    return pd.Series([Q2, H2, P22, NPSH2, rpm_pump_data, rpm_curve_nom], index=['Q','H','P2','NPSH', 'RPM(Pump data)','RPM(Curve nominal)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class to hold each curve by product number/trim\n",
    "class Curve:\n",
    "    def __init__(self, pumpModel: str, dataframe):\n",
    "        self.name = pumpModel\n",
    "        self.df = dataframe\n",
    "        self.pn = dataframe.iloc[0]['ProductNumber']\n",
    "        self.frequency = dataframe.iloc[0]['Frequency']\n",
    "        self.phase = dataframe.iloc[0]['Phase']\n",
    "        self.trims = self.df['RPM(Curve nominal)'].unique().tolist()\n",
    "        self.trim_curves = {} \n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Pump Model(name={self.name}, dataframe=\\n{self.df})\"\n",
    "\n",
    "\n",
    "    def return_xy_points(self, curveType:str):\n",
    "        '''\n",
    "        Returns 2 lists: 1 - flow values, 2 - Head or Power or NPSH\n",
    "        \n",
    "        Parameters:\n",
    "        curveType (str): The list of y-values. Available options are:\n",
    "            - 'Head'\n",
    "            - 'Power'\n",
    "            - 'NPSH'\n",
    "        \n",
    "        Raises:\n",
    "        ValueError: If the action is not one of the available options.\n",
    "        '''\n",
    "        curve_types = ['Head','Power','NPSH']\n",
    "\n",
    "        if curveType not in curve_types:\n",
    "            raise ValueError(f\"Invalid Curve Type. Available options are: {', '.join(curve_types)}\")\n",
    "        else:\n",
    "            x_values = self.df['Q'].tolist()\n",
    "            y_values = self.df[curve_dict[curveType]].tolist()\n",
    "            return x_values, y_values\n",
    "    \n",
    "\n",
    "    def create_grouped_trim_curves(self):\n",
    "        '''Group entire curve df by the trim/speed column'''\n",
    "        grouped = self.df.groupby('RPM(Curve nominal)')\n",
    "        for group_trim, trim_df in grouped:\n",
    "            self.trim_curves[group_trim] = trim_df[['Q','H','P2','NPSH','RPM(Pump data)','RPM(Curve nominal)']]\n",
    "\n",
    "\n",
    "    def create_new_trim_df(self, n2):\n",
    "        \"\"\"\n",
    "        Takes in speed n2 and applies affinity laws to max available existing trim to calculate new curve data\n",
    "\n",
    "        Output: Adds a dataframe to self.trim_curves dictionary\n",
    "\n",
    "        \"\"\"\n",
    "        # Finds max existing trim and uses that as n1\n",
    "        n1 = self.max_trim\n",
    "        df1 = self.trim_curves[n1]\n",
    "\n",
    "        # Apply the affinity laws to each row of df1 to create df2\n",
    "        df2 = df1.apply(apply_affinity_laws, axis=1, args=(n2,n1))\n",
    "\n",
    "        # Add new dataframe to dictionary trim_curves\n",
    "        self.trim_curves.update({n2:df2}) \n",
    "\n",
    "        # Update Trims Property\n",
    "        self.trims = list(self.trim_curves.keys())\n",
    "\n",
    "\n",
    "    @property\n",
    "    def max_trim(self):\n",
    "        return max(self.trims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create objects from GPI Curve Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This separates the GPI curve export by groups according to ProductNumber\n",
    "df= pd.read_csv(filePath, sep=\";\", index_col=False, skip_blank_lines=False) # FOR SPE\n",
    "df = df.replace(',','.', regex=True)\n",
    "\n",
    "# Drop NaN rows before grouping\n",
    "df_non_nan = df.dropna(how='all')\n",
    "\n",
    "# Forward fill productname and curve nominal columns for grouping \n",
    "df_non_nan['Product name'] = df_non_nan['Product name'].ffill()\n",
    "df_non_nan['RPM(Curve nominal)'] = df_non_nan['RPM(Curve nominal)'].ffill()\n",
    "df_non_nan['RPM(Pump data)'] = df_non_nan['RPM(Pump data)'].ffill()\n",
    "\n",
    "# Group by the pump model column\n",
    "grouped = df_non_nan.groupby('Product name')\n",
    "\n",
    "# Make a model from each group \n",
    "group_objects = {}\n",
    "for pumpModel, group_df in grouped:\n",
    "    group_object = Curve(pumpModel=pumpModel, dataframe=group_df)\n",
    "    group_object.create_grouped_trim_curves()\n",
    "    group_objects[(f'{pumpModel}')] = group_object\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creates new speed curve data using affinity laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of models and and create new speed dataframes at n2\n",
    "n2 = 1800\n",
    "\n",
    "for object_name in group_objects:\n",
    "    model_object = group_objects[object_name]\n",
    "    model_object.create_new_trim_df(n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leverage Luke's code to write these to xml for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This points to the curve PSD template to be used\n",
    "templateDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\3 - RESOURCES\\32 GXS\"\n",
    "template = \"SKB Blank Curve PSD - Efficiency_Metric.xlsx\"\n",
    "template = os.path.join(templateDir, template)\n",
    "\n",
    "# Create a local working copy to leave template unmodified\n",
    "output_psd_file = 'SPE - new min speed curves.xlsx'\n",
    "workingCopy = shutil.copyfile(template, output_psd_file)\n",
    "wb = load_workbook(workingCopy)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add 1 curve tab to workbook for every unique curve found (avoids duplicating data in SKB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for object_name in group_objects:\n",
    "    tabName = str(object_name)\n",
    "    wb.copy_worksheet(wb['NEW']).title = tabName # Creates and renames blank PSD Tab as template for each new curve tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterate through list of unique curve names, and populate the corresponding workbook tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill PSD \n",
    "for object_name in group_objects:\n",
    "    curveSheet = wb[object_name]   \n",
    "    # Fill Curve, power/eff, NPSH data\n",
    "    baseCell = 'D7' \n",
    "    first_row_offset = 3\n",
    "\n",
    "    # Fill Speed or trim in column A\n",
    "    trims = group_objects[object_name].trims\n",
    "    for index, eachSpeedTrim in enumerate(trims):\n",
    "        cell_name = \"{}{}\".format('A', 10+index)\n",
    "        curveSheet[cell_name].value = int(eachSpeedTrim)\n",
    "        # print(f'For PN: {uniqueCurve[0]} -> cell: {cell_name} should have value: {int(eachSpeed)}. It currently has: {curveSheet[cell_name].value}')\n",
    "\n",
    "        curve_data_df = group_objects[object_name].trim_curves[eachSpeedTrim].reset_index()\n",
    "        for key, value in curve_data_df.iterrows():\n",
    "            # print(f'first_row_offset {first_row_offset}, key: {key + 21*index}')\n",
    "            curveSheet[baseCell].offset(first_row_offset + key, 0 + 21*index).value = value['Q']\n",
    "            curveSheet[baseCell].offset(first_row_offset + key, 1 + 21*index).value = value['H']\n",
    "            curveSheet[baseCell].offset(first_row_offset + key, 7 + 21*index).value = value['Q']\n",
    "            # curveSheet[baseCell].offset(first_row_offset + key, 8 + 21*index).value = value['Eta1']\n",
    "            curveSheet[baseCell].offset(first_row_offset + key, 8 + 21*index).value = value['P2']\n",
    "            curveSheet[baseCell].offset(first_row_offset + key,14 + 21*index).value = value['Q']\n",
    "            curveSheet[baseCell].offset(first_row_offset + key,15 + 21*index).value = value['NPSH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill Curve Header Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPumpFamilyName = \"SPE\"\n",
    "sheet = wb[\"Curve Header Data\"]\n",
    "sheet['B7'] = newPumpFamilyName\n",
    "baseCell = 'A1' \n",
    "first_row_offset = 10\n",
    "\n",
    "for index, object_name in enumerate(group_objects):\n",
    "    df = group_objects[object_name].df\n",
    "    max_speed = max(group_objects[object_name].trims)\n",
    "    min_speed = min(group_objects[object_name].trims)\n",
    "            \n",
    "    sheet[baseCell].offset((first_row_offset + index), 0).value = group_objects[object_name].name\n",
    "    sheet[baseCell].offset((first_row_offset + index), 2).value = df.iloc[0]['RPM(Pump data)']\n",
    "    sheet[baseCell].offset((first_row_offset + index), 0).value = group_objects[object_name].frequency\n",
    "    sheet[baseCell].offset((first_row_offset + index), 6).value = df.iloc[0]['RPM(Curve nominal)']\n",
    "    sheet[baseCell].offset((first_row_offset + index), 7).value = min_speed\n",
    "    sheet[baseCell].offset((first_row_offset + index), 8).value = max_speed\n",
    "    sheet[baseCell].offset((first_row_offset + index), 21).value = min_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save(workingCopy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87f84caef9bf4416e38bbc24a276e63f300c10e2c66374eecdd02b2ff25e7d04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
