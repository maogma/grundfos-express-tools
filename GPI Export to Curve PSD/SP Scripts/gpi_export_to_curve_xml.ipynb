{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- Implement differences between efficiency/power curve PSDs\n",
    "- Update populated curve PSD to reflect Diameter units (Cell B3), Power (B4), Pwr/Eta cell (B5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports, File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "curve_dict = {\n",
    "    'Flow':'Q',\n",
    "    'Head':'H',\n",
    "    'Power':'P2',\n",
    "    'Efficiency':'Eta2',\n",
    "    'NPSH':'NPSH'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_affinity_laws(row, n2, n1):\n",
    "    N1, N2 = n1, n2\n",
    "    Q2 = row['Q'] * (N2 / N1)\n",
    "    H2 = row['H'] * (N2 / N1)**2\n",
    "    NPSH2 = row['NPSH'] * (N2 / N1)**2\n",
    "    P22 = row['P2'] * (N2 / N1)**3\n",
    "    # P12 = row['P1'] * (N2 / N1)**3\n",
    "    return pd.Series([Q2, H2, P22, NPSH2], index=['Q','H','P2','NPSH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class to hold each curve by product number/trim\n",
    "class Curve:\n",
    "    def __init__(self, pumpModel: str, dataframe):\n",
    "        self.name = pumpModel\n",
    "        self.df = dataframe\n",
    "        self.pn = dataframe.iloc[0]['ProductNumber']\n",
    "        self.frequency = dataframe.iloc[0]['Frequency']\n",
    "        self.phase = dataframe.iloc[0]['Phase']\n",
    "        self.trims = self.df['RPM(Curve nominal)'].unique().tolist()\n",
    "        self.trim_curves = {} \n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Pump Model(name={self.name}, dataframe=\\n{self.df})\"\n",
    "\n",
    "\n",
    "    def return_xy_points(self, curveType:str):\n",
    "        '''\n",
    "        Returns 2 lists: 1 - flow values, 2 - Head or Power or NPSH\n",
    "        \n",
    "        Parameters:\n",
    "        curveType (str): The list of y-values. Available options are:\n",
    "            - 'Head'\n",
    "            - 'Power'\n",
    "            - 'NPSH'\n",
    "        \n",
    "        Raises:\n",
    "        ValueError: If the action is not one of the available options.\n",
    "        '''\n",
    "        curve_types = ['Head','Power','NPSH']\n",
    "\n",
    "        if curveType not in curve_types:\n",
    "            raise ValueError(f\"Invalid Curve Type. Available options are: {', '.join(curve_types)}\")\n",
    "        else:\n",
    "            x_values = self.df['Q'].tolist()\n",
    "            y_values = self.df[curve_dict[curveType]].tolist()\n",
    "            return x_values, y_values\n",
    "    \n",
    "\n",
    "    def create_grouped_trim_curves(self):\n",
    "        '''Group df by the trim/speed column'''\n",
    "        grouped = self.df.groupby('RPM(Curve nominal)')\n",
    "        for group_trim, trim_df in grouped:\n",
    "            self.trim_curves[group_trim] = trim_df[['Q','H','P2','NPSH']]\n",
    "        return\n",
    "\n",
    "\n",
    "    def create_new_trim_df(self, n2):\n",
    "        \"\"\"\n",
    "        Takes in speed n2 and applies affinity laws to max available existing trim to calculate new curve data\n",
    "\n",
    "        Output: Adds a dataframe to self.trim_curves dictionary\n",
    "\n",
    "        \"\"\"\n",
    "        # Finds max existing trim and uses that as n1\n",
    "        n1 = self.max_trim\n",
    "        df1 = self.trim_curves[n1]\n",
    "\n",
    "        # Apply the function to each row of df1 to create df2\n",
    "        df2 = df1.apply(apply_affinity_laws, axis=1, args=(n2,n1))\n",
    "\n",
    "        # Add new dataframe to dictionary trim_curves\n",
    "        self.trim_curves.update({n2:df2}) \n",
    "        return\n",
    "\n",
    "\n",
    "    @property\n",
    "    def max_trim(self):\n",
    "        return max(self.trims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the folder/file with the curve export csv\n",
    "myDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\1 - PROJECTS\\SPE Integration\\SPE_PumpCurve\"\n",
    "# myDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\2 - AREAS\\Alpha GXS Integration\\Curve PSD\\Archive\"\n",
    "myFile = \"PumpCurves.csv\"\n",
    "filePath = os.path.join(myDir, myFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\104092\\AppData\\Local\\Temp\\ipykernel_89188\\464911907.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_non_nan['Product name'] = df_non_nan['Product name'].ffill()\n",
      "C:\\Users\\104092\\AppData\\Local\\Temp\\ipykernel_89188\\464911907.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_non_nan['RPM(Curve nominal)'] = df_non_nan['RPM(Curve nominal)'].ffill()\n"
     ]
    }
   ],
   "source": [
    "# This separates the GPI curve export by groups according to ProductNumber\n",
    "df= pd.read_csv(filePath, sep=\";\", index_col=False, skip_blank_lines=False) # FOR SPE\n",
    "# df= pd.read_csv(filePath, index_col=False, skip_blank_lines=False) # For ALPHA Testing\n",
    "df = df.replace(',','.', regex=True)\n",
    "\n",
    "# Drop NaN rows before grouping\n",
    "df_non_nan = df.dropna(how='all')\n",
    "\n",
    "# Forward fill productname and curve nominal columns for grouping \n",
    "df_non_nan['Product name'] = df_non_nan['Product name'].ffill()\n",
    "df_non_nan['RPM(Curve nominal)'] = df_non_nan['RPM(Curve nominal)'].ffill()\n",
    "\n",
    "# Group by the pump model column\n",
    "grouped = df_non_nan.groupby('Product name')\n",
    "\n",
    "# Make a model from each group \n",
    "group_objects = {}\n",
    "for pumpModel, group_df in grouped:\n",
    "    group_object = Curve(pumpModel=pumpModel, dataframe=group_df)\n",
    "    group_object.create_grouped_trim_curves()\n",
    "    group_objects[(f'{pumpModel}')] = group_object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of models and and create new speed dataframes at n2\n",
    "n2 = 1800\n",
    "\n",
    "for object_name in group_objects:\n",
    "    model_object = group_objects[object_name]\n",
    "    model_object.create_new_trim_df(n2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING \n",
    "# x_list, y_list = group_objects['ALPHA1 15-55F'].return_xy_points('Head')\n",
    "# max_trim = group_objects['SPE 150S250-7'].max_trim\n",
    "# group_objects['SPE 150S250-7'].trim_curves[max_trim]\n",
    "# group_objects['SPE 150S250-7'].trim_curves[1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leverage Luke's code to write these to xml for deployment\n",
    "\n",
    "# Write to excel for data validation, or plot with matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_min_max_values(myList):\n",
    "\n",
    "#     min_speed = myList[-1]\n",
    "#     max_speed = myList[0]\n",
    "#     max_nominal = max_speed\n",
    "\n",
    "#     return min_speed, max_nominal, max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findSpeedCells(my_df):\n",
    "#     \"\"\" function to find which cell to start populating curve data based on RPM\"\"\"\n",
    "#     # from openpyxl.utils.cell import coordinate_from_string, column_index_from_string, get_column_letter\n",
    "#     from openpyxl.utils.cell import get_column_letter\n",
    "#     speedCells = []\n",
    "    \n",
    "#     max_cols = 21 * len(my_df.RPM.unique())\n",
    "#     row = 7    \n",
    "#     first_col = 4\n",
    "#     diameter_cols = list(range(first_col,max_cols,21))\n",
    "    \n",
    "#     for item in diameter_cols:\n",
    "#         col = get_column_letter(item)\n",
    "#         cell_coordinate = \"{}{}\".format(col,row)\n",
    "#         speedCells.append(cell_coordinate)      \n",
    "\n",
    "#     return(speedCells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curveDataByPartNumber(data) -> dict:\n",
    "    \"\"\"Creates dictionary of dataframes for each PN \"\"\"\n",
    "    import math\n",
    "    \n",
    "    # This will become a dictionary with keys=pns and values=curve_data_dataframes\n",
    "    dict_curveDataByPn = {}\n",
    "    \n",
    "    # Iterate through each row in pump curve data export \n",
    "    for index, value in data.iterrows():    \n",
    "        \n",
    "        # When a PN is encountered:\n",
    "        # if not math.isnan(value['ProductNumber']):\n",
    "        #     currentProductNumber = int(value['ProductNumber'])\n",
    "        if type(value['ProductNumber']) == str:\n",
    "            currentProductNumber = value['ProductNumber']\n",
    "            \n",
    "            # Resets list for each PN\n",
    "            listOfFlows = []\n",
    "            listOfHeads = []\n",
    "            listOfPow = []\n",
    "            listOfSpeeds = []\n",
    "            listOfNPSH = []\n",
    "            \n",
    "        # Recording Q/H values to lists\n",
    "        if value['RPM(Curve nominal)'] > 0:\n",
    "            listOfFlows.append(value['Q'])\n",
    "            listOfHeads.append(value['H'])\n",
    "            listOfNPSH.append(value['NPSH'])\n",
    "            listOfPow.append(value['P1'])\n",
    "            listOfSpeeds.append(value['RPM(Curve nominal)'])\n",
    "            \n",
    "        # At end of Q/H values, store in dataframe before moving to next PN, or when end of data is reached\n",
    "        if pd.isna(value['Q']) and pd.isna(value['H']) or (index == len(data)-1):    \n",
    "            zipped = list(zip(listOfFlows, listOfHeads, listOfPow, listOfNPSH, listOfSpeeds))\n",
    "            df = pd.DataFrame(zipped, columns=['Q','H','P1', 'NPSH','RPM'])\n",
    "\n",
    "            # Drop rows that have NaNs, then add df to dictionary\n",
    "            df = df.dropna()\n",
    "            dict_curveDataByPn.update({currentProductNumber:df})\n",
    "\n",
    "            continue\n",
    "\n",
    "    return dict_curveDataByPn\n",
    "    \n",
    "# Creates dictionary with part numbers as keys, curves as dataframes for each key\n",
    "curveDataDict = curveDataByPartNumber(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curveDataMatches(curveDataDict):  \n",
    "    \"\"\" Create list of PNs that share curve data \"\"\"\n",
    "\n",
    "    curveDataCopy = curveDataDict.copy()\n",
    "    listOfLists = []\n",
    "    \n",
    "    for eachPN, eachDF in curveDataDict.items():  \n",
    "        listOfPNs = []\n",
    "        for key, value in curveDataCopy.items():\n",
    "            if value.equals(eachDF):\n",
    "                listOfPNs.append(key)\n",
    "        \n",
    "        if listOfPNs not in listOfLists:\n",
    "            listOfLists.append(listOfPNs)\n",
    "    \n",
    "    # print(f'list of lists: {listOfLists}')\n",
    "    # print(f'list of pns: {listOfPNs}')\n",
    "    \n",
    "    return listOfLists\n",
    "    \n",
    "# Creates list of which part numbers share curve data\n",
    "uniqueCurvePartnumbers = curveDataMatches(curveDataDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_a_curve(list_unique_curves):  # WORKING. DO NOT MODIFY YET\n",
    "#     \"\"\" CREATE new tabs for each unique curve family \"\"\"\n",
    "    \n",
    "#     global wb\n",
    "#     tab_to_copy = wb['NEW'] \n",
    "    \n",
    "#     partnumbers = []\n",
    "#     min_speeds = []\n",
    "#     nom_speeds = []\n",
    "#     max_speeds = []\n",
    "    \n",
    "#     # Add a tab for each unique curve\n",
    "#     for item in list_unique_curves: \n",
    "        \n",
    "#         list_of_speeds = []\n",
    "\n",
    "#         # Add 1 tab\n",
    "#         tabName = str(item[0])\n",
    "#         # print(tabName)\n",
    "#         wb.copy_worksheet(tab_to_copy).title = tabName\n",
    "\n",
    "#         # Fill in all speeds/trims in column A\n",
    "#         for key, value in curveDataDict[tabName].iterrows():\n",
    "#             list_of_speeds.append(value['RPM'])\n",
    "        \n",
    "#         speed_set = sorted(set(list_of_speeds), reverse=True)\n",
    "#         # print(tabName, speed_set)  \n",
    "        \n",
    "#         for index, eachSpeed in enumerate(speed_set):\n",
    "#             cell_name = \"{}{}\".format('A', 10+index)\n",
    "#             curveSheet = wb[tabName]\n",
    "#             curveSheet[cell_name].value = int(eachSpeed)\n",
    "\n",
    "#             min_rpm, nom_rpm, max_rpm = get_min_max_values(speed_set)\n",
    "            \n",
    "#             partnumbers.append(tabName)\n",
    "#             min_speeds.append(min_rpm)\n",
    "#             nom_speeds.append(nom_rpm)\n",
    "#             max_speeds.append(max_rpm)\n",
    "            \n",
    "#             zipped = list(zip(partnumbers, min_speeds, nom_speeds, max_speeds))\n",
    "#             df = pd.DataFrame(zipped, columns=['Partnumber','Min RPM','Nominal RPM', 'Max RPM'])\n",
    "        \n",
    "#     return df\n",
    "    \n",
    "# # Adds curve tabs for each unique curve\n",
    "# # minmax_speeds_df = add_a_curve(uniqueCurvePartnumbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 1 curve tab to workbook for every unique curve found (avoids duplicating data in SKB)\n",
    "for item in uniqueCurvePartnumbers: \n",
    "    tabName = str(item[0])\n",
    "    wb.copy_worksheet(wb['NEW']).title = tabName # Creates and renames blank PSD Tab as template for each new curve tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variable_speeds(df) -> list:\n",
    "    ''' Takes curve data in dataframe format, and returns list of all unique speeds for variable speed pumps'''\n",
    "    list_of_rpms = []\n",
    "\n",
    "    for key, value in df.iterrows():\n",
    "        list_of_rpms.append(value['RPM'])\n",
    "    \n",
    "    list_of_rpms = sorted(set(list_of_rpms), reverse=True)\n",
    "\n",
    "    return list_of_rpms\n",
    "\n",
    "# Iterate through list of unique curve names, and populate the corresponding workbook tab\n",
    "for uniqueCurve in uniqueCurvePartnumbers:\n",
    "    curveSheet = wb[uniqueCurve[0]]\n",
    "    curve_data_df = curveDataDict[uniqueCurve[0]]\n",
    "    \n",
    "    # Fill Speed or trim in column A\n",
    "    speed_set = extract_variable_speeds(curve_data_df)\n",
    "\n",
    "    for index, eachSpeed in enumerate(speed_set):\n",
    "        cell_name = \"{}{}\".format('A', 10+index)\n",
    "        curveSheet[cell_name].value = int(eachSpeed)\n",
    "        # print(f'For PN: {uniqueCurve[0]} -> cell: {cell_name} should have value: {int(eachSpeed)}. It currently has: {curveSheet[cell_name].value}')\n",
    "\n",
    "    # Fill Curve, power/eff, NPSH data\n",
    "    cellName = 'D7' \n",
    "    first_row_offset = 3\n",
    "\n",
    "    for key, value in curve_data_df.iterrows():\n",
    "        curveSheet[cellName].offset(first_row_offset + key, 0).value = value['Q']\n",
    "        curveSheet[cellName].offset(first_row_offset + key, 1).value = value['H']\n",
    "        curveSheet[cellName].offset(first_row_offset + key, 7).value = value['Q']\n",
    "        # curveSheet[cellName].offset(first_row_offset + key, 8).value = value['Eta1']\n",
    "        curveSheet[cellName].offset(first_row_offset + key, 8).value = value['P1']\n",
    "        curveSheet[cellName].offset(first_row_offset + key,14).value = value['Q']\n",
    "        curveSheet[cellName].offset(first_row_offset + key,15).value = value['NPSH']\n",
    "\n",
    "    # Fill out corresponding row in Curve Header Data Tab\n",
    "    # sheet = wb[\"Curve Header Data\"]\n",
    "    # sheet['B7'] = \"SP\"\n",
    "\n",
    "    # cellName = 'A1' \n",
    "    # first_row_offset = 10\n",
    "\n",
    "    # for index, speedData in curve_data_df.iterrows():\n",
    "    #     print(f'Current pn: {uniqueCurve[0]}')\n",
    "    #     print(f'{speedData}')\n",
    "\n",
    "\n",
    "    #     sheet[cellName].offset((first_row_offset + index), 0).value = uniqueCurve[0]\n",
    "    #     sheet[cellName].offset((first_row_offset + index), 2).value = speedData['RPM']\n",
    "    #     sheet[cellName].offset((first_row_offset + index), 6).value = speedData['RPM']\n",
    "    #     sheet[cellName].offset((first_row_offset + index), 7).value = speedData['RPM']\n",
    "    #     sheet[cellName].offset((first_row_offset + index), 8).value = speedData['RPM']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def speeds_for_curve_header_data():\n",
    "    # # partnumbers = []\n",
    "    # # min_speeds = []\n",
    "    # # nom_speeds = []\n",
    "    # # max_speeds = []\n",
    "\n",
    "    # min_rpm, nom_rpm, max_rpm = get_min_max_values(speed_set)\n",
    "\n",
    "    # partnumbers.append(tabName)\n",
    "    # min_speeds.append(min_rpm)\n",
    "    # nom_speeds.append(nom_rpm)\n",
    "    # max_speeds.append(max_rpm)\n",
    "\n",
    "    # zipped = list(zip(partnumbers, min_speeds, nom_speeds, max_speeds))\n",
    "    # df = pd.DataFrame(zipped, columns=['Partnumber','Min RPM','Nominal RPM', 'Max RPM'])\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fill out Curve Header Data Tab\n",
    "# newPumpFamilyName = \"SP\"\n",
    "# sheet = wb[\"Curve Header Data\"]\n",
    "# sheet['B7'] = newPumpFamilyName\n",
    "\n",
    "# cellName = 'A1' \n",
    "# first_row_offset = 10\n",
    "\n",
    "# for index, speedData in df_of_speeds.iterrows():\n",
    "#     sheet[cellName].offset((first_row_offset + index), 0).value = speedData['Partnumber']\n",
    "#     sheet[cellName].offset((first_row_offset + index), 2).value = speedData['Nominal RPM']\n",
    "#     sheet[cellName].offset((first_row_offset + index), 6).value = speedData['Nominal RPM']\n",
    "#     sheet[cellName].offset((first_row_offset + index), 7).value = speedData['Min RPM']\n",
    "#     sheet[cellName].offset((first_row_offset + index), 8).value = speedData['Max RPM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillCurveHeaderDataTab(df_of_speeds):\n",
    "    global wb\n",
    "    newPumpFamilyName = \"SP\"\n",
    "    sheet = wb[\"Curve Header Data\"]\n",
    "\n",
    "    cellName = 'A1' \n",
    "    first_row_offset = 10\n",
    "\n",
    "    for index, speedData in df_of_speeds.iterrows():\n",
    "        sheet[cellName].offset((first_row_offset + index), 0).value = speedData['Partnumber']\n",
    "        sheet[cellName].offset((first_row_offset + index), 2).value = speedData['Nominal RPM']\n",
    "        sheet[cellName].offset((first_row_offset + index), 6).value = speedData['Nominal RPM']\n",
    "        sheet[cellName].offset((first_row_offset + index), 7).value = speedData['Min RPM']\n",
    "        sheet[cellName].offset((first_row_offset + index), 8).value = speedData['Max RPM']\n",
    "\n",
    "    sheet['B7'] = newPumpFamilyName\n",
    "    wb.save(workingCopy)\n",
    "\n",
    "    return\n",
    "\n",
    "# fillCurveHeaderDataTab(minmax_speeds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of PNs that share curve data, and inserts tab to illustrate\n",
    "curveFamilySheet = wb.create_sheet(\"Shared Curves\", 2)\n",
    "\n",
    "for index, family in enumerate(uniqueCurvePartnumbers):\n",
    "    row = index + 1  # Excel doesn't like 0-indexes\n",
    "\n",
    "    # Fill 1st column in spreadsheet\n",
    "    curveFamilySheet.cell(row=row, column=1).value = \"Curve \" + str(row)\n",
    "\n",
    "    # Fill 2nd (or more) columns with partnumbers that share curves\n",
    "    if len(family) == 1:\n",
    "        curveFamilySheet.cell(row=row, column=2).value = family[0]\n",
    "        # print('length of family is 1')\n",
    "    else:\n",
    "        curveFamilySheet.cell(row=row, column=2).value = family[0]\n",
    "        curveFamilySheet.cell(row=row, column=3).value = family[1]\n",
    "        # print(f'family[0]: {family[0]}, family[1]: {family[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save changes to excel sheet\n",
    "wb.save(workingCopy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87f84caef9bf4416e38bbc24a276e63f300c10e2c66374eecdd02b2ff25e7d04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
