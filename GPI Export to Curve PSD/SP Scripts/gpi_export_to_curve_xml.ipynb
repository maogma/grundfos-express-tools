{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- Implement differences between efficiency/power curve PSDs\n",
    "- Update populated curve PSD to reflect Diameter units (Cell B3), Power (B4), Pwr/Eta cell (B5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports, File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "curve_dict = {\n",
    "    'Flow':'Q',\n",
    "    'Head':'H',\n",
    "    'Power':'P2',\n",
    "    'Efficiency':'Eta2',\n",
    "    'NPSH':'NPSH'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the folder/file with the curve export csv\n",
    "myDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\1 - PROJECTS\\SPE Integration\\SPE_PumpCurve\"\n",
    "myFile = \"PumpCurves.csv\"\n",
    "filePath = os.path.join(myDir, myFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function Definitions and Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affinity Laws function\n",
    "def apply_affinity_laws(row, n2, n1):\n",
    "    N1, N2 = n1, n2\n",
    "    Q2 = row['Q'] * (N2 / N1)\n",
    "    H2 = row['H'] * (N2 / N1)**2\n",
    "    NPSH2 = row['NPSH'] * (N2 / N1)**2\n",
    "    P22 = row['P2'] * (N2 / N1)**3\n",
    "    # P12 = row['P1'] * (N2 / N1)**3\n",
    "    return pd.Series([Q2, H2, P22, NPSH2], index=['Q','H','P2','NPSH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class to hold each curve by product number/trim\n",
    "class Curve:\n",
    "    def __init__(self, pumpModel: str, dataframe):\n",
    "        self.name = pumpModel\n",
    "        self.df = dataframe\n",
    "        self.pn = dataframe.iloc[0]['ProductNumber']\n",
    "        self.frequency = dataframe.iloc[0]['Frequency']\n",
    "        self.phase = dataframe.iloc[0]['Phase']\n",
    "        self.trims = self.df['RPM(Curve nominal)'].unique().tolist()\n",
    "        self.trim_curves = {} \n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Pump Model(name={self.name}, dataframe=\\n{self.df})\"\n",
    "\n",
    "\n",
    "    def return_xy_points(self, curveType:str):\n",
    "        '''\n",
    "        Returns 2 lists: 1 - flow values, 2 - Head or Power or NPSH\n",
    "        \n",
    "        Parameters:\n",
    "        curveType (str): The list of y-values. Available options are:\n",
    "            - 'Head'\n",
    "            - 'Power'\n",
    "            - 'NPSH'\n",
    "        \n",
    "        Raises:\n",
    "        ValueError: If the action is not one of the available options.\n",
    "        '''\n",
    "        curve_types = ['Head','Power','NPSH']\n",
    "\n",
    "        if curveType not in curve_types:\n",
    "            raise ValueError(f\"Invalid Curve Type. Available options are: {', '.join(curve_types)}\")\n",
    "        else:\n",
    "            x_values = self.df['Q'].tolist()\n",
    "            y_values = self.df[curve_dict[curveType]].tolist()\n",
    "            return x_values, y_values\n",
    "    \n",
    "\n",
    "    def create_grouped_trim_curves(self):\n",
    "        '''Group entire curve df by the trim/speed column'''\n",
    "        grouped = self.df.groupby('RPM(Curve nominal)')\n",
    "        for group_trim, trim_df in grouped:\n",
    "            self.trim_curves[group_trim] = trim_df[['Q','H','P2','NPSH']]\n",
    "\n",
    "\n",
    "    def create_new_trim_df(self, n2):\n",
    "        \"\"\"\n",
    "        Takes in speed n2 and applies affinity laws to max available existing trim to calculate new curve data\n",
    "\n",
    "        Output: Adds a dataframe to self.trim_curves dictionary\n",
    "\n",
    "        \"\"\"\n",
    "        # Finds max existing trim and uses that as n1\n",
    "        n1 = self.max_trim\n",
    "        df1 = self.trim_curves[n1]\n",
    "\n",
    "        # Apply the function to each row of df1 to create df2\n",
    "        df2 = df1.apply(apply_affinity_laws, axis=1, args=(n2,n1))\n",
    "\n",
    "        # Add new dataframe to dictionary trim_curves\n",
    "        self.trim_curves.update({n2:df2}) \n",
    "\n",
    "\n",
    "    @property\n",
    "    def max_trim(self):\n",
    "        return max(self.trims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create objects from GPI Curve Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\104092\\AppData\\Local\\Temp\\ipykernel_89188\\2750130057.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_non_nan['Product name'] = df_non_nan['Product name'].ffill()\n",
      "C:\\Users\\104092\\AppData\\Local\\Temp\\ipykernel_89188\\2750130057.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_non_nan['RPM(Curve nominal)'] = df_non_nan['RPM(Curve nominal)'].ffill()\n"
     ]
    }
   ],
   "source": [
    "# This separates the GPI curve export by groups according to ProductNumber\n",
    "df= pd.read_csv(filePath, sep=\";\", index_col=False, skip_blank_lines=False) # FOR SPE\n",
    "df = df.replace(',','.', regex=True)\n",
    "\n",
    "# Drop NaN rows before grouping\n",
    "df_non_nan = df.dropna(how='all')\n",
    "\n",
    "# Forward fill productname and curve nominal columns for grouping \n",
    "df_non_nan['Product name'] = df_non_nan['Product name'].ffill()\n",
    "df_non_nan['RPM(Curve nominal)'] = df_non_nan['RPM(Curve nominal)'].ffill()\n",
    "\n",
    "# Group by the pump model column\n",
    "grouped = df_non_nan.groupby('Product name')\n",
    "\n",
    "# Make a model from each group \n",
    "group_objects = {}\n",
    "for pumpModel, group_df in grouped:\n",
    "    group_object = Curve(pumpModel=pumpModel, dataframe=group_df)\n",
    "    group_object.create_grouped_trim_curves()\n",
    "    group_objects[(f'{pumpModel}')] = group_object\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creates new speed curve data using affinity laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of models and and create new speed dataframes at n2\n",
    "n2 = 1800\n",
    "\n",
    "for object_name in group_objects:\n",
    "    model_object = group_objects[object_name]\n",
    "    model_object.create_new_trim_df(n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writes curve data to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine DataFrames from the dictionary into a single DataFrame\n",
    "def combine_dataframes(dict_of_dfs):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for speed, df in dict_of_dfs.items():\n",
    "        # Add a column for the speed\n",
    "        df['Speed'] = speed\n",
    "        # Append to the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Write to excel for data validation, or plot with matplotlib\n",
    "# Create Excel Sheet Tabs, 1 for each curve\n",
    "output_file = 'SPE Added Minimum Speed Curves.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    # Loop through each curve object\n",
    "    for object_name in group_objects:\n",
    "        curve_obj = group_objects[object_name]\n",
    "        combined_df = combine_dataframes(curve_obj.trim_curves)\n",
    "            \n",
    "        # Write the combined DataFrame to an Excel sheet\n",
    "        combined_df.to_excel(writer, sheet_name=object_name, index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leverage Luke's code to write these to xml for deployment\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87f84caef9bf4416e38bbc24a276e63f300c10e2c66374eecdd02b2ff25e7d04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
