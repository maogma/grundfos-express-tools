{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- Implement differences between efficiency/power curve PSDs\n",
    "- Update populated curve PSD to reflect Diameter units (Cell B3), Power (B4), Pwr/Eta cell (B5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports, File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from openpyxl import load_workbook\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the folder/file with the curve export csv\n",
    "myDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\10-19 Projects\\15 SP Integration\\Curve PSD\"\n",
    "myFile = \"PumpCurves.csv\"\n",
    "filePath = os.path.join(myDir, myFile)\n",
    "\n",
    "# This creates a dataframe of the curve export csv, and fills in the RPM(curve nominal) column\n",
    "data = pd.read_csv(filePath, sep=\";\", index_col=False, skip_blank_lines=False)\n",
    "data = data.replace(',','.', regex=True)\n",
    "data['RPM(Curve nominal)'] = data['RPM(Curve nominal)'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This points to the curve PSD template to be used\n",
    "templateDir = r\"C:\\Users\\104092\\OneDrive - Grundfos\\Documents\\30-39 Resources\\32 GXS\"\n",
    "template = \"SKB Blank Curve PSD - Efficiency_Metric.xlsx\"\n",
    "template = os.path.join(templateDir, template)\n",
    "\n",
    "# Create a local working copy to leave template unmodified\n",
    "workingCopy = os.path.join(myDir, \"Populated Curve PSD - check speedset.xlsx\")\n",
    "shutil.copyfile(template, workingCopy)\n",
    "wb = load_workbook(workingCopy)      \n",
    "tab_to_copy = wb['NEW']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trim_from_modelno(model_name:str):   \n",
    "    \" Takes model name: i.e. 012-070-2P-109_Std and returns 109\"\n",
    "    res = re.search(\"-(\\d+)_Std\", model_name)\n",
    "    curve_trim_size_mm = int(res.group(1))\n",
    "    return(curve_trim_size_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curveDataByPartNumber(data) -> dict:\n",
    "    \"\"\"Creates dictionary of dataframes for each PN \"\"\"\n",
    "    import math\n",
    "    \n",
    "    # This will become a dictionary of dataframes of pns and curve data\n",
    "    dict_curveDataByPn = {}\n",
    "    \n",
    "    # Iterate through each row in pump curve data export \n",
    "    for index, value in data.iterrows():    \n",
    "    \n",
    "        # print(f\"Value[Product Number]: {value['ProductNumber']}, type: {type(value['ProductNumber'])}\")  \n",
    "        \n",
    "        # When a PN is encountered:\n",
    "        # if not math.isnan(value['ProductNumber']):\n",
    "        #     currentProductNumber = int(value['ProductNumber'])\n",
    "        if type(value['ProductNumber']) == str:\n",
    "            currentProductNumber = value['ProductNumber']\n",
    "            \n",
    "            # Resets list for each PN\n",
    "            listOfFlows = []\n",
    "            listOfHeads = []\n",
    "            listOfPow = []\n",
    "            listOfSpeeds = []\n",
    "            listOfNPSH = []\n",
    "            \n",
    "        # Recording Q/H values to lists\n",
    "        if value['RPM(Curve nominal)'] > 0:\n",
    "            listOfFlows.append(value['Q'])\n",
    "            listOfHeads.append(value['H'])\n",
    "            listOfNPSH.append(value['NPSH'])\n",
    "            listOfPow.append(value['P1'])\n",
    "            listOfSpeeds.append(value['RPM(Curve nominal)'])\n",
    "            \n",
    "        # At end of Q/H values, store in dataframe before moving to next PN, or when end of data is reached\n",
    "        if pd.isna(value['Q']) and pd.isna(value['H']) or (index == len(data)-1):    \n",
    "            zipped = list(zip(listOfFlows, listOfHeads, listOfPow, listOfNPSH, listOfSpeeds))\n",
    "            df = pd.DataFrame(zipped, columns=['Q','H','P1', 'NPSH','RPM'])\n",
    "\n",
    "            # Drop rows that have NaNs, then add df to dictionary\n",
    "            df = df.dropna()\n",
    "            dict_curveDataByPn.update({currentProductNumber:df})\n",
    "\n",
    "            continue\n",
    "\n",
    "    return dict_curveDataByPn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_values(myList):\n",
    "\n",
    "    min_speed = myList[-1]\n",
    "    max_speed = myList[0]\n",
    "    max_nominal = max_speed\n",
    "\n",
    "    return min_speed, max_nominal, max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_a_curve(list_unique_curves):  \n",
    "#     \"\"\" CREATE new tabs for each unique curve family \"\"\"\n",
    "    \n",
    "#     global wb\n",
    "    \n",
    "#     partnumbers = []\n",
    "#     min_speeds = []\n",
    "#     nom_speeds = []\n",
    "#     max_speeds = []\n",
    "#     # Add a tab for each unique curve\n",
    "#     for item in list_unique_curves: \n",
    "        \n",
    "#         list_of_speeds = []\n",
    "\n",
    "#         # Add 1 tab\n",
    "#         tabName = str(item[0])\n",
    "#         # print(tabName)\n",
    "#         wb.copy_worksheet(tab_to_copy).title = tabName\n",
    "             \n",
    "#         # Fill in all speeds in column A\n",
    "#         for key, value in curveDataDict[tabName].iterrows():\n",
    "#             list_of_speeds.append(value['RPM'])\n",
    "        \n",
    "#         speed_set = sorted(set(list_of_speeds), reverse=True)\n",
    "#         # print(tabName, speed_set)  \n",
    "        \n",
    "#         for index, eachSpeed in enumerate(speed_set):\n",
    "#             cell_name = \"{}{}\".format('A', 10+index)\n",
    "#             curveSheet = wb[tabName]\n",
    "#             curveSheet[cell_name].value = int(eachSpeed)\n",
    "\n",
    "#             min_rpm, nom_rpm, max_rpm = get_min_max_values(speed_set)\n",
    "            \n",
    "#             partnumbers.append(tabName)\n",
    "#             min_speeds.append(min_rpm)\n",
    "#             nom_speeds.append(nom_rpm)\n",
    "#             max_speeds.append(max_rpm)\n",
    "            \n",
    "#             zipped = list(zip(partnumbers, min_speeds, nom_speeds, max_speeds))\n",
    "#             df = pd.DataFrame(zipped, columns=['Partnumber','Min RPM','Nominal RPM', 'Max RPM'])\n",
    "        \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_a_curve(list_unique_curves):  \n",
    "    \"\"\" CREATE new tabs for each unique curve family \"\"\"\n",
    "    \n",
    "    global wb\n",
    "    \n",
    "    partnumbers = []\n",
    "    min_speeds = []\n",
    "    nom_speeds = []\n",
    "    max_speeds = []\n",
    "    # Add a tab for each unique curve\n",
    "    for item in list_unique_curves: \n",
    "        \n",
    "        list_of_speeds = []\n",
    "\n",
    "        # Add 1 tab\n",
    "        tabName = str(item[0])\n",
    "        # print(tabName)\n",
    "        wb.copy_worksheet(tab_to_copy).title = tabName\n",
    "             \n",
    "        # Fill in all speeds in column A\n",
    "        for key, value in curveDataDict[tabName].iterrows():\n",
    "            list_of_speeds.append(value['RPM'])\n",
    "        \n",
    "        speed_set = sorted(set(list_of_speeds), reverse=True)\n",
    "        # print(tabName, speed_set)  \n",
    "        \n",
    "        for index, eachSpeed in enumerate(speed_set):\n",
    "            cell_name = \"{}{}\".format('A', 10+index)\n",
    "            curveSheet = wb[tabName]\n",
    "            curveSheet[cell_name].value = int(eachSpeed)\n",
    "\n",
    "            min_rpm, nom_rpm, max_rpm = get_min_max_values(speed_set)\n",
    "            \n",
    "            partnumbers.append(tabName)\n",
    "            min_speeds.append(min_rpm)\n",
    "            nom_speeds.append(nom_rpm)\n",
    "            max_speeds.append(max_rpm)\n",
    "            \n",
    "            zipped = list(zip(partnumbers, min_speeds, nom_speeds, max_speeds))\n",
    "            df = pd.DataFrame(zipped, columns=['Partnumber','Min RPM','Nominal RPM', 'Max RPM'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findSpeedCells(my_df):\n",
    "#     \"\"\" function to find which cell to start populating curve data based on RPM\"\"\"\n",
    "#     # from openpyxl.utils.cell import coordinate_from_string, column_index_from_string, get_column_letter\n",
    "#     from openpyxl.utils.cell import get_column_letter\n",
    "#     speedCells = []\n",
    "    \n",
    "#     max_cols = 21 * len(my_df.RPM.unique())\n",
    "#     row = 7    \n",
    "#     first_col = 4\n",
    "#     diameter_cols = list(range(first_col,max_cols,21))\n",
    "    \n",
    "#     for item in diameter_cols:\n",
    "#         col = get_column_letter(item)\n",
    "#         cell_coordinate = \"{}{}\".format(col,row)\n",
    "#         speedCells.append(cell_coordinate)      \n",
    "\n",
    "#     return(speedCells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curveFiller(pn_vs_curves_dict):\n",
    "    \"\"\" fills curve tables in each tab \"\"\"\n",
    "    global wb\n",
    "    cellName = 'D7' \n",
    "    first_row_offset = 3\n",
    "\n",
    "    # Iterate through each tab in workbook\n",
    "    for sheet in wb.worksheets:\n",
    "        try:\n",
    "            sheetname = int(sheet.title)\n",
    "        except ValueError:\n",
    "            sheetname = sheet.title\n",
    "\n",
    "        # Only process tabs that contain curve data\n",
    "        # if sheetname[-4:] == \"_Std\":\n",
    "        for model_name, curve_dataframe in pn_vs_curves_dict.items():             \n",
    "            if model_name == sheetname:\n",
    "\n",
    "                # Iterate through dataframe row by row and fill out each row in PSD    \n",
    "                for key, value in curve_dataframe.iterrows():\n",
    "                    sheet[cellName].offset(first_row_offset + key, 0).value = value['Q']\n",
    "                    sheet[cellName].offset(first_row_offset + key, 1).value = value['H']\n",
    "                    sheet[cellName].offset(first_row_offset + key, 7).value = value['Q']\n",
    "                    # sheet[cellName].offset(first_row_offset + key, 8).value = value['Eta1']\n",
    "                    sheet[cellName].offset(first_row_offset + key, 8).value = value['P1']\n",
    "                    sheet[cellName].offset(first_row_offset + key,14).value = value['Q']\n",
    "                    sheet[cellName].offset(first_row_offset + key,15).value = value['NPSH']     \n",
    "\n",
    "        print(list(sheet.values))\n",
    "\n",
    "    return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addCurveFamiliesTab():\n",
    "    \"\"\" Create list of PNs that share curve data, and inserts tab to illustrate \"\"\"\n",
    "    \n",
    "    global wb    \n",
    "    curveFamilySheet = wb.create_sheet(\"Shared Curves\", 2)\n",
    "    \n",
    "    for index, family in enumerate(uniqueCurvePartnumbers):\n",
    "        row = index + 1  # Excel doesn't like 0-indexes\n",
    "\n",
    "        # Fill 1st column in spreadsheet\n",
    "        curveFamilySheet.cell(row=row, column=1).value = \"Curve \" + str(row)\n",
    "\n",
    "        # Fill 2nd (or more) columns with partnumbers that share curves\n",
    "        if len(family) == 1:\n",
    "            curveFamilySheet.cell(row=row, column=2).value = family[0]\n",
    "            # print('length of family is 1')\n",
    "        else:\n",
    "            curveFamilySheet.cell(row=row, column=2).value = family[0]\n",
    "            curveFamilySheet.cell(row=row, column=3).value = family[1]\n",
    "            # print(f'family[0]: {family[0]}, family[1]: {family[1]}')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curveDataMatches(curveDataDict):  \n",
    "    \"\"\" Create list of PNs that share curve data \"\"\"\n",
    "\n",
    "    curveDataCopy = curveDataDict.copy()\n",
    "    listOfLists = []\n",
    "    \n",
    "    for eachPN, eachDF in curveDataDict.items():  \n",
    "        listOfPNs = []\n",
    "        for key, value in curveDataCopy.items():\n",
    "            if value.equals(eachDF):\n",
    "                listOfPNs.append(key)\n",
    "        \n",
    "        if listOfPNs not in listOfLists:\n",
    "            listOfLists.append(listOfPNs)\n",
    "    \n",
    "    # print(f'list of lists: {listOfLists}')\n",
    "    # print(f'list of pns: {listOfPNs}')\n",
    "    \n",
    "    return listOfLists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillCurveHeaderDataTab(df_of_speeds):\n",
    "    global wb\n",
    "    newPumpFamilyName = \"SP\"\n",
    "    sheet = wb[\"Curve Header Data\"]\n",
    "\n",
    "    cellName = 'A1' \n",
    "    first_row_offset = 10\n",
    "\n",
    "    for index, speedData in df_of_speeds.iterrows():\n",
    "        sheet[cellName].offset((first_row_offset + index), 0).value = speedData['Partnumber']\n",
    "        sheet[cellName].offset((first_row_offset + index), 2).value = speedData['Nominal RPM']\n",
    "        sheet[cellName].offset((first_row_offset + index), 6).value = speedData['Nominal RPM']\n",
    "        sheet[cellName].offset((first_row_offset + index), 7).value = speedData['Min RPM']\n",
    "        sheet[cellName].offset((first_row_offset + index), 8).value = speedData['Max RPM']\n",
    "\n",
    "    # sheet['B7'] = newPumpFamilyName\n",
    "    # wb.save(workingCopy)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dictionary with part numbers as keys, curves as dataframes for each key\n",
    "curveDataDict = curveDataByPartNumber(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates list of which part numbers share curve data\n",
    "uniqueCurvePartnumbers = curveDataMatches(curveDataDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds curve tabs for each unique curve\n",
    "minmax_speeds_df = add_a_curve(uniqueCurvePartnumbers)\n",
    "# add_a_curve(uniqueCurvePartnumbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillCurveHeaderDataTab(minmax_speeds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fills each new curve tab\n",
    "# curveFiller(curveDataDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "addCurveFamiliesTab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save changes to excel sheet\n",
    "wb.save(workingCopy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d89935b22884bac8e846ef6a5fb14ff565b7e382ac92ebe1031401d4b8e3f29"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
